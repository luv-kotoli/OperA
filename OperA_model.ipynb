{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"OperA_model.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1cS4IeMM-EazXhQpnJfOQn-EBC8lh7_oe","authorship_tag":"ABX9TyPIzDTSsOdlXr8wy8vYUi/i"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"kzAOPB9Ktc6N"},"source":["#1. Data Download and Preporcessing\n","\n","This code only used the cholec80 dataset to do the experiment"]},{"cell_type":"code","metadata":{"id":"DVVEftg37Yo-"},"source":["!wget -c --http-user=camma_cholec80 --http-password=cholec80_unistra http://camma.u-strasbg.fr/datasets/cholec80/cholec80.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"moPsG6ltYxh_"},"source":["#!unzip -l ./cholec80.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X4LhV2No94ad"},"source":["!unzip -d ./cholec80 -n ./drive/MyDrive/cholec80.zip"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6Di3r9YNt8ry"},"source":["After downloading and unzip the cholec80 dataset, the video frames should be extracted and the extracting fps is 1fps. \n","\n","After extracting, the change_size code will remove the black margin of each frame and then resize the frames to 250*250.\n","\n","Finally, use the original phase_annotation files to extract the annotations for the model."]},{"cell_type":"code","metadata":{"id":"xZ3FW70HzjcV"},"source":["import cv2\n","import os\n","import PIL\n","import pandas as pd\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xTgi0wrz83Op"},"source":["def change_size(image):\n"," \n","    binary_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","    _, binary_image2 = cv2.threshold(binary_image, 15, 255, cv2.THRESH_BINARY)\n","    binary_image2 = cv2.medianBlur(binary_image2, 19)  # filter the noise, need to adjust the parameter based on the dataset\n","    x = binary_image2.shape[0]\n","    y = binary_image2.shape[1]\n","\n","    edges_x = []\n","    edges_y = []\n","    for i in range(x):\n","        for j in range(10,y-10):\n","            if binary_image2.item(i, j) != 0:\n","                edges_x.append(i)\n","                edges_y.append(j)\n","    \n","    if not edges_x:\n","        return image\n","\n","    left = min(edges_x)  # left border\n","    right = max(edges_x)  # right\n","    width = right - left  \n","    bottom = min(edges_y)  # bottom\n","    top = max(edges_y)  # top\n","    height = top - bottom  \n","\n","    pre1_picture = image[left:left + width, bottom:bottom + height]  \n","\n","    #print(pre1_picture.shape) \n","    \n","    return pre1_picture  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sVaGmm5b6hyB"},"source":["for video in range(1,81):\n","  frame_path = './cholec80/frames/{}'.format(video)\n","  print(frame_path)\n","  cap= cv2.VideoCapture('./cholec80/videos/video{:02d}.mp4'.format(video))\n","  if not os.path.exists(frame_path):\n","    os.makedirs(frame_path)\n","  i=0\n","  while(cap.isOpened()):\n","      imsave_path = os.path.join(frame_path,'{}.jpg'.format(i//25))\n","      ret, frame = cap.read()\n","      if ret == False:\n","        break\n","      if not i%25==0:\n","        i+=1\n","        cv2.waitKey(1)\n","        continue\n","      \n","      dim = (int(frame.shape[1]/frame.shape[0]*300), 300)\n","        \n","      frame = cv2.resize(frame,dim)\n","      frame = change_size(frame)\n","      img_result = cv2.resize(frame,(250,250))\n","      #print(img_result.shape)\n","      #print(img_result.dtype)\n","\n","      img_result = cv2.cvtColor(img_result, cv2.COLOR_BGR2RGB)\n","      img_result = PIL.Image.fromarray(img_result)\n","      #print(img_result.mode)\n","\n","\n","      if i%25==0:\n","        print(imsave_path)\n","        imsave_path = os.path.join(frame_path,'{}.jpg'.format(i//25))\n","        cv2.imwrite(imsave_path,img_result)\n","      i+=1\n","      cv2.waitKey(1)\n","\n","  cap.release()\n","  cv2.destroyAllWindows()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rvG9ggvD952N"},"source":["for i in range(1,81):\n","  phase_path = './cholec80/phase_annotations/video{:02d}-phase.txt'.format(i)\n","  df = pd.read_csv(phase_path,sep='\\t')\n","  result_df = df[::25]\n","  idx = np.arange(0,len(result_df))\n","  result_df.iloc[:,0] = idx\n","  #print(result_df.head())\n","  #result_df.iloc[:,1]= df.iloc[::25,1]\n","  result_df.to_csv('./cholec80/annotations/{}.txt'.format(i),sep='\\t',index=False,header=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Jr0ZLn2StmBR"},"source":["#2. Feature Extractor Network training (ResNet50)\n","\n","According to the paper, a ResNet50 model is trained to extract features from frames. The dataset is seperated by 60 for training and validation, 20 for testing. In this part, I use 5-fold cross validation to train the ResNet50 model and extract the frame features by using the best model of each fold.\n","\n","The training and testing dataset is randomly selected."]},{"cell_type":"code","metadata":{"id":"fHyUETH3cSLZ"},"source":["# This zip file is the extracted frames from cholec80 dataset.\n","#!cp ./drive/MyDrive/cholec_extracted.zip ./\n","#!unzip cholec_extracted.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3DZTHMCRFZa0","executionInfo":{"status":"ok","timestamp":1635994297385,"user_tz":-480,"elapsed":12005,"user":{"displayName":"Xx Yu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgIqmYua040dq-ZDSfHKi1K9oP3mLHlRWtt3F10=s64","userId":"10216398448151910347"}}},"source":["import torch\n","from torch import nn\n","import torch.nn.functional as F\n","import torch.nn.init as init\n","from torchvision import models,transforms\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision.datasets.folder import default_loader\n","\n","from sklearn.model_selection import KFold\n","\n","import os\n","import math\n","import random\n","import numpy as np\n","import pandas as pd\n","import copy\n","from tqdm import tqdm"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WtmmxqQPvc9S","executionInfo":{"status":"ok","timestamp":1635994297386,"user_tz":-480,"elapsed":13,"user":{"displayName":"Xx Yu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgIqmYua040dq-ZDSfHKi1K9oP3mLHlRWtt3F10=s64","userId":"10216398448151910347"}},"outputId":"0d3be02c-9773-43cf-a2dd-ab67b69a1e08"},"source":["!nvidia-smi\n","print(torch.cuda.is_available())"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Thu Nov  4 02:50:08 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   47C    P0    31W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","True\n"]}]},{"cell_type":"code","metadata":{"id":"B5L2D8z7vjfi"},"source":["class ResNet50(nn.Module):\n","  def __init__(self,num_classes=1000):\n","    super(ResNet50,self).__init__()\n","    resnet = models.resnet50(pretrained=True)\n","    self.share = nn.Sequential()\n","    self.share.add_module('conv1',resnet.conv1)\n","    self.share.add_module('bn1',resnet.bn1)\n","    self.share.add_module('relu',resnet.relu)\n","    self.share.add_module('maxpool',resnet.maxpool)\n","    self.share.add_module('layer1',resnet.layer1)\n","    self.share.add_module('layer2',resnet.layer2)\n","    self.share.add_module('layer3',resnet.layer3)\n","    self.share.add_module('layer4',resnet.layer4)\n","    self.share.add_module('avgpool',resnet.avgpool)\n","    self.fc = nn.Linear(2048,num_classes)\n","    #self.softmax = nn.Softmax()\n","  def forward(self,x):\n","    x = x.view(-1,3,224,224)\n","    x = self.share.forward(x)\n","    feature = x.view(x.size(0),-1)\n","    #print(x.shape,feature.shape)\n","    y = self.fc(feature)\n","\n","    return feature,y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5E1P1WGCFyzS","executionInfo":{"status":"ok","timestamp":1635994335443,"user_tz":-480,"elapsed":633,"user":{"displayName":"Xx Yu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgIqmYua040dq-ZDSfHKi1K9oP3mLHlRWtt3F10=s64","userId":"10216398448151910347"}}},"source":["phase2label_dict = {\n","  'cholec80':{\n","    'Preparation':0,\n","    'CalotTriangleDissection':1,\n","    'ClippingCutting':2,\n","    'GallbladderDissection':3,\n","    'GallbladderPackaging':4,\n","    'CleaningCoagulation':5,\n","    'GallbladderRetraction':6\n","  }\n","}"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"dCCgC4Q4GGTK","executionInfo":{"status":"ok","timestamp":1635994336197,"user_tz":-480,"elapsed":2,"user":{"displayName":"Xx Yu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgIqmYua040dq-ZDSfHKi1K9oP3mLHlRWtt3F10=s64","userId":"10216398448151910347"}}},"source":["def phase2label(phases,phase2label_dict):\n","  labels = [phase2label_dict[phase] if phase in phase2label_dict.keys() else len(phase2label_dict) for phase in phases]\n","  labels = np.array(labels)\n","  return labels"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"B5lt5VpxVng9"},"source":["# to see if the number of frames is equal to the number of labels\n","root_path = './cholec80'\n","for i in range(1,81):\n","  frame_path = os.path.join(root_path,'frames/{}'.format(i))\n","  len1 = len(os.listdir(frame_path))\n","  phase_path = os.path.join(root_path,'annotations/{}.txt'.format(i))\n","  phase = pd.read_csv(os.path.join(phase_path),sep='\\t',header=None)\n","  len2 = len(phase)\n","  #print(len1-len2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0pmuW8lCG155","executionInfo":{"status":"ok","timestamp":1635993052811,"user_tz":-480,"elapsed":749,"user":{"displayName":"Xx Yu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgIqmYua040dq-ZDSfHKi1K9oP3mLHlRWtt3F10=s64","userId":"10216398448151910347"}}},"source":["# generate frame dataset\n","class FrameData(Dataset):\n","  def __init__(self,dataset,root,label_folder='annotations',frame_folder='frames',load_list=[]):\n","    self.dataset = dataset\n","    self.root = root\n","    self.imgs = []\n","    self.labels = []\n","\n","    frame_path = os.path.join(root,frame_folder)\n","    label_path = os.path.join(root,label_folder)\n","\n","    for i in load_list:\n","      frame_fold = os.path.join(frame_path,str(i))\n","      frame_len = len(os.listdir(frame_fold))\n","      \n","      labels = pd.read_csv(os.path.join(label_path,'{}.txt'.format(i)),sep='\\t',header=None)\n","      labels = labels.loc[:,1]\n","      labels = np.array(labels)\n","      labels = phase2label(labels,phase2label_dict[self.dataset])\n","      label_len = len(labels)\n","      assert frame_len == label_len\n","\n","      for idx in range(0,frame_len):\n","        self.imgs.append(os.path.join(frame_fold,'{}.jpg'.format(idx)))\n","        self.labels.append(labels[idx])\n","    self.transform = self.get_transform()\n","    print('Load Dataset {} with {} frames'.format(self.dataset,len(self.imgs)))\n","\n","  def __len__(self):\n","    return len(self.imgs)\n","\n","  def __getitem__(self,item):\n","    img,labels,img_path = self.transform(default_loader(self.imgs[item])),self.labels[item],self.imgs[item]\n","    #print(len(img),len(labels),len(img_path))\n","    return img,labels,img_path\n","\n","  def get_transform(self):\n","    return transforms.Compose([\n","            transforms.Resize((224,224)),\n","            transforms.ToTensor()\n","    ])\n"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"id":"H_JLJ_vYcOQ6"},"source":["####unit test###########\n","#black_list = np.arange(1,80)\n","#load_list = [1]\n","#dataset = FrameData('cholec80','./cholec80',load_list=load_list)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XNv3Jw8zjRT_"},"source":["learning_rate = 1e-4\n","epochs = 3\n","batch_size= 128\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","loss_layer = nn.CrossEntropyLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ewyeu33hd6HC"},"source":["def cross_valid_train(model,save_dir,feature_dir,train_loader,test_loader):\n","  global learning_rate,epochs\n","  lr = copy.deepcopy(learning_rate)\n","  if not os.path.exists(save_dir):\n","    os.makedirs(save_dir)\n","  model.to(device)\n","  for epoch in range(1,epochs+1):\n","    torch.cuda.empty_cache()\n","    \n","    if epoch%2==0:\n","      lr = lr*0.5\n","    model.train()\n","\n","    correct = 0\n","    total = 0\n","    loss_item =0\n","\n","    optimizer = torch.optim.Adam(model.parameters(),lr,weight_decay=1e-5)\n","\n","    for (imgs,labels,img_path) in tqdm(train_loader):\n","      imgs,labels = imgs.to(device),labels.to(device)\n","      feature,y = model(imgs) # shape 224*224*3\n","      print(y.shape,labels.shape)\n","      loss = loss_layer(y,labels)\n","      loss_item += loss.item()\n","      _,prediction = torch.max(y.data,1)\n","      correct += ((prediction==labels).sum()).item()\n","      total += len(prediction)\n","\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","\n","    train_acc = correct/total\n","    train_loss = loss_item/total\n","    \n","    test_acc,test_loss = cross_valid_test(model,feature_dir,test_loader,save_feature=False)\n","      \n","    print('Training Epoch {}: train_acc:{:.4f},train_loss:{:.4f},test_acc:{:.4f},test_loss:{:.4f}'.format(epoch,train_acc,train_loss,test_acc,test_loss))\n","    torch.save(model.state_dict(),os.path.join(save_dir,'train_{}_{:.0f}_{:.0f}.pth'.format(epoch,test_acc*10000,test_loss*10000)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a2SKjpuh6_Pz"},"source":["def cross_valid_test(model,feature_dir,test_loader,err_dir,save_feature=True):\n","  print('Testing, Saving feature:{}'.format(save_feature))\n","  err_df = pd.DataFrame(columns=['video_num','frame_num','err'])\n","  model.eval()\n","  model.to(device)\n","  correct = 0\n","  total = 0\n","  loss_item = 0\n","  with torch.no_grad():\n","    torch.cuda.empty_cache()\n","    for (imgs,labels,img_path) in tqdm(test_loader):\n","      video_num,frame_name= img_path[0].split('/')[-2],img_path[0].split('/')[-1]\n","      imgs,labels = imgs.to(device),labels.to(device)\n","      feature,y = model(imgs)\n","      loss = loss_layer(y,labels)\n","      loss_item += loss.item()\n","      _,prediction = torch.max(y.data,1)\n","      correct += ((prediction==labels).sum()).item()\n","      total += len(prediction)\n","\n","      err_df.loc[len(err_df)] = [int(video_num),int(frame_name.split('.')[0]),loss.item()]\n","\n","      if save_feature == True:\n","        assert len(imgs)==1 # set batch_size=1 to extract features\n","        feature = feature.to('cpu').numpy()\n","        video_num,frame_name= img_path[0].split('/')[-2],img_path[0].split('/')[-1]\n","        save_path = os.path.join(feature_dir,video_num)\n","        if not os.path.exists(save_path):\n","          os.makedirs(save_path)\n","        np.save(os.path.join(save_path,frame_name.split('.')[0]+'.npy'),feature)\n","    test_acc = correct/total\n","    test_loss = loss_item/total\n","  err_df.to_csv(err_dir,sep=',',index=False)\n","  return test_acc,test_loss\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2emAq3nQvE_2"},"source":["# training progress\n","dataset = 'cholec80'\n","k = 5\n","random_seed = 1024\n","np.random.seed(random_seed) # set numpy random seed\n","random.seed(random_seed) # set python random seed\n","\n","dataset_list = np.arange(1,81)\n","train_list = np.array(random.sample(dataset_list.tolist(),60)) # get training list randomly\n","test_list = np.setdiff1d(dataset_list,train_list) # get remaining test list\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pqIBZ6ak8OJv"},"source":["##################### unit test ########################\n","#k = 2\n","#dataset_list = np.arange(1,4)\n","#train_list = np.array(random.sample(dataset_list.tolist(),3)) # get training list randomly\n","#test_list = np.setdiff1d(dataset_list,train_list) # get remaining test list\n","###########################################################\n","\n","\n","kf = KFold(k,shuffle=True,random_state=random_seed)\n","valid_split = kf.split(train_list)\n","\n","for k, (train_idx,valid_idx) in enumerate(valid_split):\n","  resnet = ResNet50(num_classes=7)\n","  train_dataset = FrameData(dataset,'./drive/MyDrive/cholec80',load_list=train_list[train_idx])\n","  valid_dataset = FrameData(dataset,'./drive/MyDrive/cholec80',load_list=train_list[valid_idx])\n","\n","  train_dataloader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True,drop_last=False)\n","  valid_dataloader = DataLoader(valid_dataset,batch_size=batch_size,shuffle=True,drop_last=False)\n","\n","  model_save_dir = './drive/MyDrive/OperA/{}/cross_valid/{}'.format(dataset,k)\n","  feature_save_dir = './drive/MyDrive/OperA/{}/cross_valid_feature/'.format(dataset)\n","  print('Cross Valid {}: model saved at -> {}'.format(k,model_save_dir))\n","\n","  cross_valid_train(resnet,model_save_dir,feature_save_dir,train_dataloader,valid_dataloader)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v0iheUnlDHUC","executionInfo":{"status":"ok","timestamp":1635861420040,"user_tz":-480,"elapsed":520,"user":{"displayName":"Xx Yu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgIqmYua040dq-ZDSfHKi1K9oP3mLHlRWtt3F10=s64","userId":"10216398448151910347"}},"outputId":"9271db6c-f1ed-4b50-9512-ed932c4d3ddf"},"source":["print(test_list)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[ 2  4 10 16 17 21 26 27 32 35 37 43 51 56 59 60 65 69 77 79]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fvp3ZXXIC03j","executionInfo":{"status":"ok","timestamp":1635776574981,"user_tz":-480,"elapsed":664780,"user":{"displayName":"Xx Yu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgIqmYua040dq-ZDSfHKi1K9oP3mLHlRWtt3F10=s64","userId":"10216398448151910347"}},"outputId":"c4c230ea-06c2-4bbb-edb5-dea0c50f8201"},"source":["resnet = ResNet50(num_classes=7)\n","\n","model_path = './drive/MyDrive/OperA/{}/cross_valid/4/best.pth'.format(dataset)\n","resnet.load_state_dict(torch.load(model_path))\n","\n","test_dataset = FrameData(dataset,'./cholec80',load_list=test_list)\n","test_dataloader = DataLoader(test_dataset,batch_size=1,shuffle=False,drop_last=False)\n","\n","feature_save_dir = './OperA/{}/cross_valid_feature/'.format(dataset)\n","err_dir = './drive/MyDrive/OperA/{}/err_dir/test_err.csv'.format(dataset)\n","cross_valid_test(resnet,feature_save_dir,test_dataloader,err_dir)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Load Dataset cholec80 with 44042 frames\n","Testing, Saving feature:True\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 44042/44042 [11:03<00:00, 66.39it/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["(0.8095000227055992, 0.6373712011547304)"]},"metadata":{},"execution_count":31}]},{"cell_type":"markdown","metadata":{"id":"LAgtBiouyyj8"},"source":["After training , the frame-wise features are extracted through the ResNet50 model and merge the features to video features. Besides, I also saved the CEE loss error of each frame which will be used in the next model."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"akegYiqiX40a","executionInfo":{"status":"ok","timestamp":1635778666094,"user_tz":-480,"elapsed":2089380,"user":{"displayName":"Xx Yu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgIqmYua040dq-ZDSfHKi1K9oP3mLHlRWtt3F10=s64","userId":"10216398448151910347"}},"outputId":"06a282f3-31ef-4df5-c56e-7a65c498e605"},"source":["dataset = 'cholec80'\n","k = 5\n","random_seed = 1024\n","np.random.seed(random_seed) # set numpy random seed\n","random.seed(random_seed) # set python random seed\n","\n","dataset_list = np.arange(1,81)\n","train_list = np.array(random.sample(dataset_list.tolist(),60)) # get training list randomly\n","#test_list = np.setdiff1d(dataset_list,train_list) # get remaining test list\n","\n","kf = KFold(k,shuffle=True,random_state=random_seed)\n","valid_split = kf.split(train_list)\n","\n","for k, (train_idx,valid_idx) in enumerate(valid_split):\n","  print('cross valid fold {} is extracting'.format(k))\n","  print(train_list[valid_idx])\n","  resnet = ResNet50(num_classes=7)\n","  model_path = './drive/MyDrive/OperA/{}/cross_valid/{}/best.pth'.format(dataset,k)\n","  resnet.load_state_dict(torch.load(model_path))\n","\n","  valid_dataset = FrameData(dataset,'./{}'.format(dataset),load_list=train_list[valid_idx])\n","  valid_dataloader = DataLoader(valid_dataset,batch_size=1,shuffle=False,drop_last=False)\n","\n","  feature_save_dir = './OperA/{}/cross_valid_feature/'.format(dataset)\n","  err_dir = './drive/MyDrive/OperA/{}/err_dir/valid_{}_err.csv'.format(dataset,k)\n","  cross_valid_test(resnet,feature_save_dir,valid_dataloader,err_dir)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cross valid fold 0 is extracting\n","[50 67 78 75 14 34 54  9 11 15  8 74]\n","Load Dataset cholec80 with 23385 frames\n","Testing, Saving feature:True\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 23385/23385 [05:49<00:00, 66.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["cross valid fold 1 is extracting\n","[ 3 66 47  6 41 52 45 49 30 46 73  5]\n","Load Dataset cholec80 with 30481 frames\n","Testing, Saving feature:True\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30481/30481 [07:33<00:00, 67.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["cross valid fold 2 is extracting\n","[57 18 53 29 71 58 76  1 64 25 68 44]\n","Load Dataset cholec80 with 32735 frames\n","Testing, Saving feature:True\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 32735/32735 [08:08<00:00, 66.99it/s]\n"]},{"output_type":"stream","name":"stdout","text":["cross valid fold 3 is extracting\n","[62 13 48 31 23 40 80 22 12 19 63 38]\n","Load Dataset cholec80 with 25944 frames\n","Testing, Saving feature:True\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 25944/25944 [06:18<00:00, 68.55it/s]\n"]},{"output_type":"stream","name":"stdout","text":["cross valid fold 4 is extracting\n","[42 70 20 28 39  7 24 72 55 61 33 36]\n","Load Dataset cholec80 with 27991 frames\n","Testing, Saving feature:True\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 27991/27991 [06:48<00:00, 68.44it/s]\n"]}]},{"cell_type":"code","metadata":{"id":"H1dCwzaeGytK"},"source":["def video_feature_gen(feature_dir,target_dir):\n","  if not os.path.exists(target_dir):\n","    os.makedirs(target_dir)\n","  video_list = np.array(os.listdir(feature_dir),dtype='uint8')\n","  for video_idx in tqdm(video_list):\n","    frame_path = os.path.join(feature_dir,str(video_idx))\n","    frame_list = os.listdir(frame_path)\n","    num_of_frames = len(frame_list)\n","    video_feature = []\n","    for i in range(0,num_of_frames):\n","      img_path = os.path.join(frame_path,'{}.npy'.format(i))\n","      video_feature.append(np.load(img_path))\n","    video_feature = np.concatenate(video_feature,axis=0)\n","\n","    np.save(os.path.join(target_dir,'{}.npy'.format(video_idx)),video_feature)\n","    print('video {} have been saved'.format(video_idx))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aF8obUkOJsfI"},"source":["video_feature_dir = './drive/MyDrive/OperA/{}/video_feature'.format(dataset)\n","video_feature_gen(feature_save_dir,video_feature_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9jUBcx8fzEQh"},"source":["#3. OperA model\n","In this part, I implemented the remaining OperA model with self-attention according to the paper. \n","The model used 11 self-attention layer and used a self-defined loss function. They are all implemented in my code. \n","\n","However, I cannot get a good result with the code. There may be areas where my implementation is wrong or some parameters are different with the authors code."]},{"cell_type":"code","metadata":{"id":"qjURYbo-hCHf","executionInfo":{"status":"ok","timestamp":1635994299958,"user_tz":-480,"elapsed":8,"user":{"displayName":"Xx Yu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgIqmYua040dq-ZDSfHKi1K9oP3mLHlRWtt3F10=s64","userId":"10216398448151910347"}}},"source":["class FeadForwardNetwork(nn.Module):\n","  def __init__(self,hidden_size,filter_size,dropout=0.1):\n","    super(FeadForwardNetwork,self).__init__()\n","\n","    self.layer1 = nn.Linear(filter_size,hidden_size)\n","    self.layer2 = nn.Linear(hidden_size,filter_size)\n","    self.dropout = nn.Dropout(dropout)\n","\n","    init.xavier_normal_(self.layer1.weight)\n","    init.constant_(self.layer1.bias,0)\n","    init.xavier_normal_(self.layer2.weight)\n","    init.constant_(self.layer2.bias,0)\n","\n","  def forward(self,x):\n","    x = self.layer1(x)\n","    x = F.relu(x)\n","    x = self.dropout(x)\n","    x = self.layer2(x)\n","    return x"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"zWNSRrCyLQgj","executionInfo":{"status":"ok","timestamp":1635994299959,"user_tz":-480,"elapsed":8,"user":{"displayName":"Xx Yu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgIqmYua040dq-ZDSfHKi1K9oP3mLHlRWtt3F10=s64","userId":"10216398448151910347"}}},"source":["class Attention(nn.Module):\n","  def __init__(self,feature_size,d_model,dropout=0.1,is_first=False):\n","    super(Attention,self).__init__()\n","    self.is_first = is_first\n","    self.d_model = d_model\n","    self.d = 64\n","    self.linear_f = nn.Linear(feature_size,d_model)\n","    #self.linear_q = nn.Linear(d_model,d_model)\n","    #self.linear_k = nn.Linear(d_model,d_model)\n","    #self.linear_v = nn.Linear(d_model,d_model)\n","    self.dropout = nn.Dropout(dropout)\n","    self.norm = nn.LayerNorm(d_model)\n","    self.fc = FeadForwardNetwork(512,d_model)\n","\n","    init.xavier_normal_(self.linear_f.weight)\n","\n","  def forward(self,x):\n","    if self.is_first==True:\n","      x = self.linear_f(x)\n","    x = x.view(-1,self.d_model)\n","    q,k,v = (x,x,x)\n","    #q = self.linear_q(x)\n","    #k = self.linear_k(x)\n","    #v = self.linear_v(x)\n","    \n","    mask = 1-np.triu(np.ones((q.size(0),q.size(0)))).astype('bool')\n","    mask = torch.from_numpy(mask).cuda()\n","\n","    attention,scores_sm = self.calculation(q,k,v,mask)\n","    attention = self.norm(x+attention)\n","    fc_output = self.fc(attention)\n","    output = self.norm(attention+fc_output)\n","\n","\n","    if self.is_first==True:\n","      # Normalized Frame-Wise Attention\n","      n_up = torch.sum(scores_sm,axis=0).cuda()\n","      n_down = torch.arange(q.size(0),0,-1).cuda()\n","      n = n_up/n_down\n","      return output,n\n","    else:\n","      return output\n","  \n","  def calculation(self,q,k,v,mask=None):\n","    scores = torch.matmul(q,k.transpose(-1,-2))/math.sqrt(self.d)\n","\n","    if mask is not None:\n","      #mask = mask.unsqueeze(1)\n","      scores = scores.masked_fill(mask==0,-1e9)\n","    scores_sm = F.softmax(scores,dim=-1)\n","\n","    if self.dropout is not None:\n","      scores_sm = self.dropout(scores_sm)\n","\n","    output = torch.matmul(scores_sm,v)\n","    return output,scores_sm"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"brY695RrmH-x","executionInfo":{"status":"ok","timestamp":1635994299960,"user_tz":-480,"elapsed":8,"user":{"displayName":"Xx Yu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgIqmYua040dq-ZDSfHKi1K9oP3mLHlRWtt3F10=s64","userId":"10216398448151910347"}}},"source":["class OperA(nn.Module):\n","  def __init__(self,num_classes=7):\n","    super(OperA,self).__init__()\n","    self.layer1 = Attention(2048,192,is_first=True)\n","    self.layer2 = Attention(192,192)\n","    self.layer3 = Attention(192,192)\n","    self.layer4 = Attention(192,192)\n","    self.layer5 = Attention(192,192)\n","    self.layer6 = Attention(192,192)\n","    self.layer7 = Attention(192,192)\n","    self.layer8 = Attention(192,192)\n","    self.layer9 = Attention(192,192)\n","    self.layer10 = Attention(192,192)\n","    self.layer11 = Attention(192,192)\n","    self.fc = nn.Linear(192,num_classes)\n","    init.xavier_normal_(self.fc.weight)\n","  def forward(self,x):\n","    x,n = self.layer1(x)\n","    x = self.layer2(x)\n","    x = self.layer3(x)\n","    x = self.layer4(x)\n","    x = self.layer5(x)\n","    x = self.layer6(x)\n","    x = self.layer7(x)\n","    x = self.layer8(x)\n","    x = self.layer9(x)\n","    x = self.layer10(x)\n","    x = self.layer11(x)\n","    output = self.fc(x)\n","    output = output.view(-1,output.size(-1))\n","    #print(output.shape,' : final output shape')\n","    return output,n\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"g8btOoEEzb0O","executionInfo":{"status":"ok","timestamp":1635994299961,"user_tz":-480,"elapsed":9,"user":{"displayName":"Xx Yu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgIqmYua040dq-ZDSfHKi1K9oP3mLHlRWtt3F10=s64","userId":"10216398448151910347"}}},"source":["class VideoFeature(Dataset):\n","  def __init__(self,dataset,root,err_path,feature_folder='video_feature',label_folder='annotations',load_list=[]):\n","    self.dataset = dataset\n","    self.root = root\n","    self.features = []\n","    self.labels = []\n","    self.err = []\n","\n","    feature_path = os.path.join(root,feature_folder)\n","    label_path = os.path.join(root,label_folder)\n","\n","    err_pd = pd.read_csv(err_path,sep=',')\n","\n","    for i in load_list:\n","      feature = np.load(os.path.join(feature_path,'{}.npy'.format(i)))\n","\n","      labels = pd.read_csv(os.path.join(label_path,'{}.txt'.format(i)),sep='\\t',header=None)\n","      labels = labels.loc[:,1]\n","      labels = np.array(labels)\n","      labels = phase2label(labels,phase2label_dict[self.dataset])\n","      label_len = len(labels)\n","      \n","      err = err_pd[err_pd['video_num']==i]\n","      err = err.iloc[:,2]\n","      err = np.array(err,dtype='float32')\n","      err_len = len(err)\n","\n","      self.features.append(feature)\n","      self.labels.append(labels)\n","      self.err.append(err)\n","      #print(feature.shape,label_len,err_len)\n","    self.freq_list = self.get_class_freq()\n","    print('Load Dataset {} with {} video features'.format(self.dataset,len(self.features)))\n","\n","  def __len__(self):\n","    return len(self.features)\n","\n","  def __getitem__(self,item):\n","    feature,label,err = self.features[item],self.labels[item],self.err[item]\n","    freq_list = self.freq_list\n","    return feature,label,err,freq_list\n","\n","  def get_class_freq(self):\n","    freq_list = []\n","    labels_all = np.concatenate(self.labels,axis=0)\n","    for i in range(7):\n","      freq_list.append(round(sum(labels_all==i)/len(labels_all),4))\n","    return freq_list\n"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FaBcY6ReEFDe","executionInfo":{"status":"ok","timestamp":1635987301922,"user_tz":-480,"elapsed":16156,"user":{"displayName":"Xx Yu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgIqmYua040dq-ZDSfHKi1K9oP3mLHlRWtt3F10=s64","userId":"10216398448151910347"}},"outputId":"57ba5599-5333-42f6-dedd-0d64cc60578b"},"source":["######################### unit test ###################\n","root_path = './drive/MyDrive/OperA/cholec80'\n","err_path = os.path.join(root_path,'err_dir/dataset_err.csv')\n","load_list = np.arange(1,5)\n","test_vf = VideoFeature('cholec80',root_path,err_path,load_list=load_list)\n","freq_list = test_vf.get_class_freq()\n","print(freq_list)\n","##########################################################"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Load Dataset cholec80 with 4 video features\n","[0.0695, 0.54, 0.0619, 0.1956, 0.0233, 0.0759, 0.0338]\n"]}]},{"cell_type":"code","metadata":{"id":"yE1bo52jpy_X","executionInfo":{"status":"ok","timestamp":1635993728284,"user_tz":-480,"elapsed":638,"user":{"displayName":"Xx Yu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgIqmYua040dq-ZDSfHKi1K9oP3mLHlRWtt3F10=s64","userId":"10216398448151910347"}}},"source":["# this function is used to generate the loss error file of the whole dataset\n","def concat_err_file(err_dir):\n","  err_file_list = os.listdir(err_dir)\n","  df = pd.DataFrame(columns=['video_num','frame_num','err'])\n","  for file_ in err_file_list:\n","    err_file = os.path.join(err_dir,file_)\n","    print(err_file)\n","    err_df = pd.read_csv(err_file,sep=',',dtype={'video_num':int,'frame_num':int})\n","    df = pd.concat([df,err_df],axis=0)\n","  df = df.sort_values(by=['video_num','frame_num'])\n","  df.to_csv(os.path.join(err_dir,'dataset_err.csv'),sep=',',index=False)"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gPd8zjmgri9E","executionInfo":{"status":"ok","timestamp":1635842250856,"user_tz":-480,"elapsed":1371,"user":{"displayName":"Xx Yu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgIqmYua040dq-ZDSfHKi1K9oP3mLHlRWtt3F10=s64","userId":"10216398448151910347"}},"outputId":"28208eb7-6178-4c8a-de8c-3365abed35dc"},"source":["err_dir = './drive/MyDrive/OperA/{}/err_dir'.format(dataset)\n","concat_err_file(err_dir)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["./drive/MyDrive/OperA/cholec80/err_dir/test_err.csv\n","./drive/MyDrive/OperA/cholec80/err_dir/valid_0_err.csv\n","./drive/MyDrive/OperA/cholec80/err_dir/valid_1_err.csv\n","./drive/MyDrive/OperA/cholec80/err_dir/valid_2_err.csv\n","./drive/MyDrive/OperA/cholec80/err_dir/valid_3_err.csv\n","./drive/MyDrive/OperA/cholec80/err_dir/valid_4_err.csv\n"]}]},{"cell_type":"code","metadata":{"id":"b9R2XKiXFYwl","executionInfo":{"status":"ok","timestamp":1635994775329,"user_tz":-480,"elapsed":604,"user":{"displayName":"Xx Yu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgIqmYua040dq-ZDSfHKi1K9oP3mLHlRWtt3F10=s64","userId":"10216398448151910347"}}},"source":["def opera_train(model,model_save_dir,result_dir,train_loader,test_loader):\n","  lr = 1e-6\n","  epochs = 30\n","  if not os.path.exists(model_save_dir):\n","    os.makedirs(model_save_dir)\n","  model.to(device)\n","\n","  for epoch in range(1,epochs+1):\n","    torch.cuda.empty_cache()\n","    #if epoch%3==0:\n","    #  lr = lr*0.5\n","    model.train()\n","\n","    correct = 0\n","    total = 0\n","    loss_item = 0\n","\n","    optimizer = torch.optim.Adam(model.parameters(),lr,weight_decay=1e-5)\n","\n","    for (feature,label,err,freq_list) in tqdm(train_loader):\n","      feature,label,err = feature.to(device),label.to(device),err.to(device)\n","      output,n = model(feature)\n","      label = label.transpose(-1,-2)\n","      err = err.squeeze()\n","      #print(output.shape,n.shape,' :2')\n","      \n","\n","      # median frequency balanced cross-entropy\n","      class_freq = freq_list\n","      class_weight = [1.0/freq for freq in class_freq]\n","      class_weight = torch.Tensor(class_weight)\n","      loss_layer = nn.CrossEntropyLoss(weight=class_weight).cuda()\n","      loss = 0\n","      for i in range(len(output)):\n","        loss += loss_layer(torch.unsqueeze(output[i,:],0),label[i,:])\n","        loss += n[i]*err[i] \n","      loss = loss/len(output)\n","      loss_item +=loss.item()\n","      _,prediction = torch.max(output.data,1)\n","\n","      correct += ((prediction==label.transpose(-1,-2)).sum()).item()\n","      total += len(prediction)\n","\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","\n","    train_acc = correct/total\n","    train_loss = loss_item/total\n","    test_acc,test_loss = opera_test(model,result_dir,test_loader)\n","    print('Training Epoch {}: train_acc:{:.4f},train_loss:{},test_acc:{:.4f},test_loss:{}'.format(\n","        epoch,train_acc,train_loss,test_acc,test_loss))\n","    torch.save(model.state_dict(),os.path.join(model_save_dir,'train_{}_{:.0f}_{:.0f}.pth'.format(epoch,test_acc*10000,test_loss*10000)))"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yppt-7owGCJb","executionInfo":{"status":"ok","timestamp":1635994314918,"user_tz":-480,"elapsed":1029,"user":{"displayName":"Xx Yu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgIqmYua040dq-ZDSfHKi1K9oP3mLHlRWtt3F10=s64","userId":"10216398448151910347"}}},"source":["def opera_test(model,result_dir,test_loader,save_result=False):\n","  print('OperA model is training ,Saving result: {}'.format(save_result))\n","  model.eval()\n","  model.to(device)\n","  correct = 0\n","  total = 0\n","  loss_item = 0\n","\n","  with torch.no_grad():\n","    torch.cuda.empty_cache()\n","    for (feature,label,err,freq_list) in tqdm(test_loader):\n","      feature,label,err = feature.to(device),label.to(device),err.to(device)\n","      output,n = model(feature)\n","      label = label.transpose(-1,-2)\n","      err = err.squeeze()\n","\n","      class_freq = freq_list\n","      class_weight = [1.0/freq for freq in class_freq]\n","      class_weight = torch.Tensor(class_weight)\n","      loss_layer = nn.CrossEntropyLoss(weight=class_weight).cuda()\n","      loss = 0\n","      for i in range(len(output)):\n","        loss += loss_layer(torch.unsqueeze(output[i,:],0),label[i,:])\n","        loss += n[i]*err[i]\n","      loss = loss/len(output)\n","      loss_item +=loss.item()\n","      _,prediction = torch.max(output.data,1)\n","      correct += ((prediction==label.transpose(-1,-2)).sum()).item()\n","      total += len(prediction)\n","\n","      test_acc = correct/total\n","      test_loss = loss_item/total\n","\n","      if save_result == True:\n","        print(prediction)\n","  return test_acc,test_loss"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"jGe4GppANXNg","executionInfo":{"status":"ok","timestamp":1635994316603,"user_tz":-480,"elapsed":2,"user":{"displayName":"Xx Yu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgIqmYua040dq-ZDSfHKi1K9oP3mLHlRWtt3F10=s64","userId":"10216398448151910347"}}},"source":["dataset = 'cholec80'\n","k = 5\n","random_seed = 1024\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","np.random.seed(random_seed) # set numpy random seed\n","random.seed(random_seed) # set python random seed\n","\n","dataset_list = np.arange(1,81)\n","train_list = np.array(random.sample(dataset_list.tolist(),60)) # get training list randomly\n","test_list = np.setdiff1d(dataset_list,train_list) # get remaining test list\n","\n","kf = KFold(k,shuffle=True,random_state=random_seed)\n","valid_split = kf.split(train_list)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yZcLceB-N4KG","executionInfo":{"status":"ok","timestamp":1635994317257,"user_tz":-480,"elapsed":3,"user":{"displayName":"Xx Yu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgIqmYua040dq-ZDSfHKi1K9oP3mLHlRWtt3F10=s64","userId":"10216398448151910347"}},"outputId":"b4ec2794-f8bc-4261-8313-cbbabadac09a"},"source":["print(train_list,test_list)"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["[ 3 62 50 42 67 13 57 66 47 48 78 75 18 70 14 53 20 28 31 29 71 34 54 23\n"," 40 39  6 80 58 41 76 52  7 24 45 22  1 72 64 12  9 11 25 19 55 49 15  8\n"," 30 46 61 68 44 74 73 63 38 33  5 36] [ 2  4 10 16 17 21 26 27 32 35 37 43 51 56 59 60 65 69 77 79]\n"]}]},{"cell_type":"code","metadata":{"id":"v-po5lCwNOfp"},"source":["##################### unit test ########################\n","#dataset_list = np.arange(1,7)\n","#train_list = np.array(random.sample(dataset_list.tolist(),6)) # get training list randomly\n","#test_list = np.setdiff1d(dataset_list,train_list) # get remaining test list\n","###########################################################\n","\n","for k, (train_idx,valid_idx) in enumerate(valid_split):\n","  print('fold {} is training'.format(k))\n","  #resnet = ResNet50(num_classes=7)\n","  opera = OperA()\n","  #test_vf = VideoFeature('cholec80',root_path,err_path,load_list=load_list)\n","  root_path = './drive/MyDrive/OperA/cholec80'\n","  err_path = os.path.join(root_path,'err_dir/dataset_err.csv')\n","  train_dataset = VideoFeature(dataset,root_path,err_path,load_list=train_list[train_idx])\n","  valid_dataset = VideoFeature(dataset,root_path,err_path,load_list=train_list[valid_idx])\n","\n","  train_dataloader = DataLoader(train_dataset,batch_size=1,shuffle=False,drop_last=False)\n","  valid_dataloader = DataLoader(valid_dataset,batch_size=1,shuffle=False,drop_last=False)\n","\n","  model_save_dir = './drive/MyDrive/OperA/{}/opera_cross_valid/{}'.format(dataset,k)\n","  result_dir = './drive/MyDrive/OperA/{}/opera_result/'.format(dataset)\n","  print('Cross Valid {}: model saved at -> {}'.format(k,model_save_dir))\n","\n","  opera_train(opera,model_save_dir,result_dir,train_dataloader,valid_dataloader)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4aB3mkUK3iOx"},"source":["opera = OperA()\n","model_path = './drive/MyDrive/OperA/{}/opera_cross_valid/0/best.pth'.format(dataset)\n","opera.load_state_dict(torch.load(model_path))\n","\n","test_dataset = VideoFeature(dataset,root_path,err_path,load_list=test_list)\n","test_dataloader = DataLoader(test_dataset,batch_size=1,shuffle=False,drop_last=False)\n","opera_test(opera,result_dir,test_dataloader,save_result=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K9SQ6XLTpPY2"},"source":[""],"execution_count":null,"outputs":[]}]}